{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Instalação de pacotes no Google Colab\n",
        "# ============================================================\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install networkx matplotlib"
      ],
      "metadata": {
        "id": "nw6MqZKbxrKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Importações\n",
        "# ============================================================\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Semente para reprodutibilidade (gera os mesmos resultados em diferentes execuções)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "3M5y8UmYxtOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Construção da rede biológica toy\n",
        "# ============================================================\n",
        "num_nodes = 120     # número de nós (proteínas simuladas)\n",
        "num_edges = 2       # cada novo nó conecta-se a 2 já existentes\n",
        "G = nx.barabasi_albert_graph(num_nodes, num_edges, seed=42)\n",
        "\n",
        "print(f\"Grafo com {G.number_of_nodes()} nós e {G.number_of_edges()} arestas\")\n",
        "\n",
        "# Número de atributos (features) de cada proteína\n",
        "num_features = 10\n",
        "\n",
        "# Definição de classes reais (exemplo: núcleo=0, citoplasma=1)\n",
        "labels = np.random.randint(0, 2, size=num_nodes)\n",
        "\n",
        "# Geração de features correlacionadas com as classes\n",
        "features = np.zeros((num_nodes, num_features))\n",
        "for i in range(num_nodes):\n",
        "    if labels[i] == 0:\n",
        "        # proteínas do \"núcleo\" → valores médios positivos\n",
        "        features[i] = np.random.normal(loc=0.5, scale=0.3, size=num_features)\n",
        "    else:\n",
        "        # proteínas do \"citoplasma\" → valores médios negativos\n",
        "        features[i] = np.random.normal(loc=-0.5, scale=0.3, size=num_features)\n",
        "features = features.astype(np.float32)"
      ],
      "metadata": {
        "id": "4nXkOf-hx9ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L46UpLcyxAm1"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Preparação dos dados para a GCN\n",
        "# ============================================================\n",
        "A = nx.to_numpy_array(G)   # matriz de adjacência (ligações entre proteínas)\n",
        "I = np.eye(num_nodes)      # matriz identidade (self-loops)\n",
        "A_hat = A + I              # adiciona self-loops → cada nó se conecta a si mesmo\n",
        "\n",
        "# Normalização simétrica: D^(-1/2) * A_hat * D^(-1/2)\n",
        "D_hat = np.diag(np.sum(A_hat, axis=1))          # grau dos nós\n",
        "D_hat_inv_sqrt = np.linalg.inv(np.sqrt(D_hat))  # inverso da raiz quadrada\n",
        "A_norm = D_hat_inv_sqrt @ A_hat @ D_hat_inv_sqrt  # matriz normalizada\n",
        "\n",
        "# Conversão para tensores do PyTorch\n",
        "X = torch.tensor(features)                             # features\n",
        "Y = torch.tensor(labels, dtype=torch.long)             # rótulos\n",
        "A_norm = torch.tensor(A_norm, dtype=torch.float32)     # matriz adjacência normalizada"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Definição da GCN\n",
        "# ============================================================\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.linear = nn.Linear(in_features, out_features)  # transformação linear\n",
        "\n",
        "    def forward(self, X, A_norm):\n",
        "        # Multiplica a matriz normalizada pelas features (propagação de vizinhos)\n",
        "        # e aplica transformação linear\n",
        "        return self.linear(A_norm @ X)\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_features, hidden_size, num_classes, dropout=0.5):\n",
        "        super(GCN, self).__init__()\n",
        "        self.gcn1 = GCNLayer(in_features, hidden_size)     # primeira camada GCN\n",
        "        self.gcn2 = GCNLayer(hidden_size, num_classes)     # segunda camada GCN\n",
        "        self.dropout = nn.Dropout(dropout)                 # regularização (evita overfitting)\n",
        "\n",
        "    def forward(self, X, A_norm):\n",
        "        h = F.relu(self.gcn1(X, A_norm))   # aplica ReLU após primeira camada\n",
        "        h = self.dropout(h)                # aplica dropout\n",
        "        out = self.gcn2(h, A_norm)         # logits finais (sem softmax)\n",
        "        return out"
      ],
      "metadata": {
        "id": "_q0ps_6S6ax_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Divisão dos dados (treino, validação, teste)\n",
        "# ============================================================\n",
        "num_nodes = X.shape[0]\n",
        "idx_all = np.arange(num_nodes)\n",
        "np.random.shuffle(idx_all)  # embaralha nós\n",
        "\n",
        "# 70% treino, 15% validação, 15% teste\n",
        "train_end = int(0.70 * num_nodes)\n",
        "val_end = int(0.85 * num_nodes)\n",
        "train_idx = idx_all[:train_end]\n",
        "val_idx = idx_all[train_end:val_end]\n",
        "test_idx = idx_all[val_end:]\n"
      ],
      "metadata": {
        "id": "OILkdxBgysxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Configuração de treino\n",
        "# ============================================================\n",
        "model = GCN(num_features, hidden_size=32, num_classes=2)\n",
        "\n",
        "lr = 0.01                   # taxa de aprendizado\n",
        "weight_decay = 5e-4         # regularização L2\n",
        "max_epochs = 500            # número máximo de épocas\n",
        "patience = 20               # early stopping (paciência)\n",
        "monitor = 'val_loss'        # critério para parar (pode ser val_loss ou val_acc)\n",
        "\n",
        "# Otimizador e função de perda\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Controle do early stopping\n",
        "best_state = None\n",
        "best_metric = float('inf') if monitor == 'val_loss' else -float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "# Histórico para plots\n",
        "train_losses, val_losses = [], []\n",
        "train_accs, val_accs = [], []"
      ],
      "metadata": {
        "id": "kfes_P316fkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Função auxiliar de avaliação (loss e acurácia)\n",
        "# ============================================================\n",
        "def evaluate_model(model, X, A_norm, idx):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out = model(X, A_norm)              # logits (N, C)\n",
        "        loss = criterion(out[idx], Y[idx]).item()\n",
        "        preds = out[idx].argmax(dim=1)      # classes previstas\n",
        "        acc = (preds == Y[idx]).float().mean().item()\n",
        "    return loss, acc, preds"
      ],
      "metadata": {
        "id": "ec7TC31q6iea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Loop de treino com Early Stopping\n",
        "# ============================================================\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    # ---------------- Treino ----------------\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(X, A_norm)                              # forward\n",
        "    loss = criterion(out[train_idx], Y[train_idx])      # calcula perda\n",
        "    loss.backward()                                     # backpropagation\n",
        "    optimizer.step()                                    # atualização dos pesos\n",
        "\n",
        "    # ---------------- Avaliação ----------------\n",
        "    train_loss, train_acc, _ = evaluate_model(model, X, A_norm, train_idx)\n",
        "    val_loss, val_acc, _ = evaluate_model(model, X, A_norm, val_idx)\n",
        "\n",
        "    # salva histórico\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "    train_accs.append(train_acc)\n",
        "    val_accs.append(val_acc)\n",
        "\n",
        "    # ---------------- Early Stopping ----------------\n",
        "    current_metric = val_loss if monitor == 'val_loss' else val_acc\n",
        "    improved = (current_metric < best_metric) if monitor == 'val_loss' else (current_metric > best_metric)\n",
        "\n",
        "    if improved:\n",
        "        best_metric = current_metric\n",
        "        best_state = copy.deepcopy(model.state_dict())  # salva melhor versão\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "\n",
        "    # imprime a cada 10 épocas\n",
        "    if epoch % 10 == 0 or epoch == 1:\n",
        "        print(f\"Epoch {epoch:03d} | train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | \"\n",
        "              f\"val_loss: {val_loss:.4f} val_acc: {val_acc:.4f} | no_improve: {epochs_no_improve}\")\n",
        "\n",
        "    # para se não houver melhora após \"patience\"\n",
        "    if epochs_no_improve >= patience:\n",
        "        print(f\"Early stopping na epoch {epoch}. Melhor {monitor}: {best_metric:.4f}\")\n",
        "        break\n",
        "\n",
        "# carrega melhor modelo salvo\n",
        "if best_state is not None:\n",
        "    model.load_state_dict(best_state)"
      ],
      "metadata": {
        "id": "mo4f9E756mjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Avaliação no conjunto de teste\n",
        "# ============================================================\n",
        "test_loss, test_acc, test_preds = evaluate_model(model, X, A_norm, test_idx)\n",
        "print(f\"Teste | loss: {test_loss:.4f} | acc: {test_acc:.4f}\")"
      ],
      "metadata": {
        "id": "NN-Fzh4u22Z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Plots de aprendizado\n",
        "# ============================================================\n",
        "plt.figure(figsize=(12,4))\n",
        "\n",
        "# Curva de Loss\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_losses, label='train_loss')\n",
        "plt.plot(val_losses, label='val_loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Loss (Treino vs Val)')\n",
        "\n",
        "# Curva de Acurácia\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(train_accs, label='train_acc')\n",
        "plt.plot(val_accs, label='val_acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.title('Accuracy (Treino vs Val)')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sXqoEOHi26Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------- Rede final ----------------\n",
        "pos = nx.spring_layout(G, seed=42)\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1)\n",
        "nx.draw(G, pos, node_color=Y.numpy(), cmap=plt.cm.Set1, with_labels=False, node_size=50)\n",
        "plt.title(\"Classes reais\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "# predições para todos os nós\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    out_all = model(X, A_norm)\n",
        "    _, preds_all = torch.max(out_all, dim=1)\n",
        "nx.draw(G, pos, node_color=preds_all.numpy(), cmap=plt.cm.Set1, with_labels=False, node_size=50)\n",
        "plt.title(\"Classes previstas (modelo final)\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dat-7G8Jyuqx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}